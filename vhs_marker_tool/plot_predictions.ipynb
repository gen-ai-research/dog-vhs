{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataset import DogHeartTestDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from model import get_model\n",
    "from utils import get_transform\n",
    "from evaluate import plot_predictions\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Navigate up three levels to reach the project root\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "\n",
    "# Create the path to static/uploads\n",
    "uploads_dir = os.path.join(project_root, 'project','static', 'uploads','Images')\n",
    "uploads_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = get_model(device)\n",
    "checkpoint_path = 'final_best_model.pth' # Download at https://drive.google.com/file/d/1-nng3RxjHvUl5O6q8D8xYGoXXRdGpgKh/view?usp=drive_link\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "test_dataset = DogHeartTestDataset(uploads_dir, transforms=get_transform(512))\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "#plot_predictions(model, test_loader, device) # Due to GitHub's file upload size restrictions, only a subset of the images is displayed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "PREDICT_FOLDER = \"static/predict\"  # Directory to save .mat files\n",
    "os.makedirs(PREDICT_FOLDER, exist_ok=True)  # Ensure folder exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the Predictions to .mat files\n",
    "def calc_vhs(x: torch.Tensor):\n",
    "    \"\"\"Compute VHS value based on six predicted points.\"\"\"\n",
    "    A, B = x[..., 0:2], x[..., 2:4]\n",
    "    C, D = x[..., 4:6], x[..., 6:8]\n",
    "    E, F = x[..., 8:10], x[..., 10:12]\n",
    "\n",
    "    AB = torch.norm(A - B, p=2, dim=-1)\n",
    "    CD = torch.norm(C - D, p=2, dim=-1)\n",
    "    EF = torch.norm(E - F, p=2, dim=-1)\n",
    "\n",
    "    vhs = 6 * (AB + CD) / EF\n",
    "    return vhs\n",
    "\n",
    "def save_predictions_to_mat(image_name, predicted_points, vhs_value):\n",
    "    \"\"\"Save the predicted points and VHS value into a .mat file.\"\"\"\n",
    "    mat_data = {\n",
    "        \"six_points\": predicted_points.numpy(),  # Store predicted six points\n",
    "        \"VHS\": np.array([[vhs_value]])  # Store VHS as a single-element array\n",
    "    }\n",
    "\n",
    "    mat_filename = os.path.join(PREDICT_FOLDER, f\"{os.path.splitext(image_name)[0]}.mat\")\n",
    "    sio.savemat(mat_filename, mat_data)\n",
    "    print(f\"✅ Predictions saved to {mat_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = get_model(device)\n",
    "checkpoint_path = 'final_best_model.pth' # Download at https://drive.google.com/file/d/1-nng3RxjHvUl5O6q8D8xYGoXXRdGpgKh/view?usp=drive_link\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)\n",
    "model.load_state_dict(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in the test DataLoader: 2\n"
     ]
    }
   ],
   "source": [
    "test_dataset = DogHeartTestDataset(uploads_dir, transforms=get_transform(512))\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(f\"Number of batches in the test DataLoader: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10_12.8_1.png\n",
      "pred points=> 6\n",
      "[[271.37186 235.97198]\n",
      " [343.1939  476.76062]\n",
      " [174.53072 355.34903]\n",
      " [356.82278 275.9262 ]\n",
      " [198.82953 231.92859]\n",
      " [404.1997  164.09407]]\n",
      "vhs=> 12.486807823181152\n",
      "✅ Predictions saved in MATLAB format: static/predict/10_12.8_1.mat\n",
      "1 1_12.3_1.png\n",
      "pred points=> 6\n",
      "[[244.76201 210.54951]\n",
      " [284.64145 447.82596]\n",
      " [150.48428 322.71024]\n",
      " [320.647   281.01227]\n",
      " [152.877   140.29593]\n",
      " [360.2752  138.80406]]\n",
      "vhs=> 12.028769493103027\n",
      "✅ Predictions saved in MATLAB format: static/predict/1_12.3_1.mat\n",
      "2 2_10.8_0.png\n",
      "pred points=> 6\n",
      "[[246.73949 234.6333 ]\n",
      " [306.78677 415.8583 ]\n",
      " [195.3375  308.02878]\n",
      " [296.6527  267.6255 ]\n",
      " [212.03813 157.40602]\n",
      " [371.07993 117.36887]]\n",
      "vhs=> 10.97492504119873\n",
      "✅ Predictions saved in MATLAB format: static/predict/2_10.8_0.mat\n",
      "3 3_11.6_1.png\n",
      "pred points=> 6\n",
      "[[255.53868 195.21126]\n",
      " [351.28363 423.42432]\n",
      " [181.34215 332.7177 ]\n",
      " [327.12778 227.59262]\n",
      " [194.02226 129.62285]\n",
      " [397.69598  70.89267]]\n",
      "vhs=> 12.092692375183105\n",
      "✅ Predictions saved in MATLAB format: static/predict/3_11.6_1.mat\n",
      "4 4_10.7_00.png\n",
      "pred points=> 6\n",
      "[[257.47363 237.31537]\n",
      " [302.49384 433.56567]\n",
      " [179.0191  349.72064]\n",
      " [325.45413 288.60724]\n",
      " [176.94225 164.83234]\n",
      " [373.3791  160.01952]]\n",
      "vhs=> 10.993332862854004\n",
      "✅ Predictions saved in MATLAB format: static/predict/4_10.7_00.mat\n",
      "5 5_10.3_0.png\n",
      "pred points=> 6\n",
      "[[299.52444  160.72844 ]\n",
      " [397.1723   452.7952  ]\n",
      " [233.1101   332.27368 ]\n",
      " [387.5871   211.44118 ]\n",
      " [163.38231  143.90636 ]\n",
      " [417.69897   33.748253]]\n",
      "vhs=> 10.912802696228027\n",
      "✅ Predictions saved in MATLAB format: static/predict/5_10.3_0.mat\n",
      "6 6_8.5_0.png\n",
      "pred points=> 6\n",
      "[[228.66647 285.97333]\n",
      " [366.6131  439.20926]\n",
      " [149.8695  374.35086]\n",
      " [316.02982 306.80045]\n",
      " [166.46782 237.52888]\n",
      " [428.57013 136.08937]]\n",
      "vhs=> 8.230938911437988\n",
      "✅ Predictions saved in MATLAB format: static/predict/6_8.5_0.mat\n",
      "7 7_9.8_0.png\n",
      "pred points=> 6\n",
      "[[273.30014 259.02032]\n",
      " [310.01605 457.05875]\n",
      " [164.94893 342.9709 ]\n",
      " [322.3232  304.50247]\n",
      " [193.09094 179.15613]\n",
      " [422.06735 140.27472]]\n",
      "vhs=> 9.388531684875488\n",
      "✅ Predictions saved in MATLAB format: static/predict/7_9.8_0.mat\n",
      "0 8_10.8_00.png\n",
      "pred points=> 6\n",
      "[[268.3799  290.1409 ]\n",
      " [347.48853 459.07935]\n",
      " [205.45503 408.78192]\n",
      " [345.26923 326.36023]\n",
      " [212.11359 249.8149 ]\n",
      " [401.9432  178.16455]]\n",
      "vhs=> 10.315642356872559\n",
      "✅ Predictions saved in MATLAB format: static/predict/8_10.8_00.mat\n",
      "1 9_12.1_1.png\n",
      "pred points=> 6\n",
      "[[282.9013  254.41304]\n",
      " [381.25772 481.38507]\n",
      " [189.15805 397.16425]\n",
      " [372.58743 298.1841 ]\n",
      " [227.87473 207.89449]\n",
      " [433.89575 141.76785]]\n",
      "vhs=> 12.639200210571289\n",
      "✅ Predictions saved in MATLAB format: static/predict/9_12.1_1.mat\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "\n",
    "\n",
    "def save_predictions_to_mat(image_name, predicted_points, vhs_value):\n",
    "    \"\"\"Save predicted points and VHS in MATLAB-compatible .mat format.\"\"\"\n",
    "    mat_filename = os.path.splitext(image_name)[0] + \".mat\"\n",
    "    mat_filepath = os.path.join(PREDICT_FOLDER, mat_filename)\n",
    "\n",
    "    # Convert points to correct MATLAB format\n",
    "    mat_data = {\n",
    "        \"six_points\": np.array(predicted_points),  # Store 6 points in an array\n",
    "        \"VHS\": np.array([[vhs_value]])  # Store VHS as a 2D array\n",
    "    }\n",
    "\n",
    "    sio.savemat(mat_filepath, mat_data)\n",
    "    print(f\"✅ Predictions saved in MATLAB format: {mat_filepath}\")\n",
    "\n",
    "\n",
    "# Function to plot images with their predicted and true points (if applicable).\n",
    "def generate_predictions(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Plot predictions and print point coordinates for each image.\n",
    "    \n",
    "    - True points are shown in blue.\n",
    "    - Predicted points are shown in red.\n",
    "    - VHS values (True vs Predicted) are displayed.\n",
    "    - X1, Y1, X2, Y2 coordinates for all 6 points are printed.\n",
    "    \"\"\"\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        for data_batch in data_loader:\n",
    "            if len(data_batch) == 4:\n",
    "                image_names, images, points, vhs_gt = data_batch\n",
    "            elif len(data_batch) == 2:\n",
    "                images, image_names = data_batch\n",
    "                points, vhs_gt = None, None  # No true points for unlabeled images\n",
    "            else:\n",
    "                print(\"Unexpected batch format\")\n",
    "                continue\n",
    "            \n",
    "            images = images.to(device)\n",
    "            outputs = model(images)  # Generate predictions\n",
    "            vhs_pred = calc_vhs(outputs)  # Compute VHS values\n",
    "            \n",
    "            # Convert tensors to numpy\n",
    "            images_np = images.permute(0, 2, 3, 1).cpu().numpy()\n",
    "            outputs_np = outputs.cpu().numpy()\n",
    "            vhs_pred_np = vhs_pred.cpu().numpy()\n",
    "            \n",
    "            ## start : Loop through image names\n",
    "\n",
    "            for i,name in enumerate(image_names):\n",
    "                print(i,name)\n",
    "                img = images_np[i]\n",
    "                img = (img - img.min()) / (img.max() - img.min())  # Normalize for display\n",
    "                pred_points = outputs_np[i].reshape(-1, 2) * img.shape[0]\n",
    "                print(\"pred points=>\",len(pred_points))\n",
    "                print(pred_points)\n",
    "                pred_vhs = vhs_pred_np[i].item()\n",
    "                print(\"vhs=>\",pred_vhs)\n",
    "\n",
    "                 # Save predictions in MATLAB format\n",
    "                save_predictions_to_mat(name, pred_points, pred_vhs)\n",
    "                \n",
    "\n",
    "            ## end : Loop through image names\n",
    "\n",
    "generate_predictions(model,test_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file Platform: posix, Created on: Tue Feb  4 23:24:00 2025',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'six_points': array([[299.52444 , 160.72844 ],\n",
       "        [397.1723  , 452.7952  ],\n",
       "        [233.1101  , 332.27368 ],\n",
       "        [387.5871  , 211.44118 ],\n",
       "        [163.38231 , 143.90636 ],\n",
       "        [417.69897 ,  33.748253]], dtype=float32),\n",
       " 'VHS': array([[10.9128027]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_data = scipy.io.loadmat(\"static/predict/5_10.3_0.mat\")\n",
    "mat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[1;32m      4\u001b[0m img_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcalc_vhs\u001b[39m(x: \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute VHS value based on six predicted points.\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     A, B \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m], x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "img_size = 512\n",
    "\n",
    "def calc_vhs(x: torch.Tensor):\n",
    "    \"\"\"Compute VHS value based on six predicted points.\"\"\"\n",
    "    A, B = x[..., 0:2], x[..., 2:4]\n",
    "    C, D = x[..., 4:6], x[..., 6:8]\n",
    "    E, F = x[..., 8:10], x[..., 10:12]\n",
    "\n",
    "    AB = torch.norm(A - B, p=2, dim=-1)\n",
    "    CD = torch.norm(C - D, p=2, dim=-1)\n",
    "    EF = torch.norm(E - F, p=2, dim=-1)\n",
    "\n",
    "    vhs = 6 * (AB + CD) / EF\n",
    "    return vhs\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = get_model(device)\n",
    "#checkpoint_path = 'final_best_model.pth' # Download at https://drive.google.com/file/d/1-nng3RxjHvUl5O6q8D8xYGoXXRdGpgKh/view?usp=drive_link\n",
    "checkpoint_path = 'model_epoch_25.pth' \n",
    "checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "test_dataset = DogHeartTestDataset(\"data/Test/Images\", transforms=get_transform(512))\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "CSV_FILE = \"test_vhs_scores_25.csv\"\n",
    "\n",
    "def save_vhs_to_csv(image_name, vhs_value):\n",
    "    \"\"\"Save image filename and VHS value in a CSV file.\"\"\"\n",
    "    file_exists = os.path.isfile(CSV_FILE)\n",
    "\n",
    "    with open(CSV_FILE, mode=\"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write header if file is new\n",
    "        if not file_exists:\n",
    "            writer.writerow([\"Image Name\", \"VHS Value\"])\n",
    "\n",
    "        # Write image name and VHS value\n",
    "        writer.writerow([image_name, vhs_value])\n",
    "\n",
    "    print(f\"✅ Saved: {image_name}, VHS: {vhs_value}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "        for data_batch in test_loader:\n",
    "            if len(data_batch) == 4:\n",
    "                image_names, images, points, vhs_gt = data_batch\n",
    "            elif len(data_batch) == 2:\n",
    "                images, image_names = data_batch\n",
    "                points, vhs_gt = None, None  # No true points for unlabeled images\n",
    "            else:\n",
    "                print(\"Unexpected batch format\")\n",
    "                continue\n",
    "            \n",
    "            images = images.to(device)\n",
    "            outputs = model(images)  # Generate predictions\n",
    "            vhs_pred = calc_vhs(outputs)  # Compute VHS values\n",
    "            \n",
    "            # Convert tensors to numpy\n",
    "            images_np = images.permute(0, 2, 3, 1).cpu().numpy()\n",
    "            outputs_np = outputs.cpu().numpy()\n",
    "            vhs_pred_np = vhs_pred.cpu().numpy()\n",
    "            \n",
    "            ## start : Loop through image names\n",
    "\n",
    "            for i,name in enumerate(image_names):\n",
    "                print(i,name)\n",
    "                img = images_np[i]\n",
    "                img = (img - img.min()) / (img.max() - img.min())  # Normalize for display\n",
    "                pred_points = outputs_np[i].reshape(-1, 2) * img.shape[0]\n",
    "                #print(\"pred points=>\",len(pred_points))\n",
    "                #print(pred_points)\n",
    "                pred_vhs = vhs_pred_np[i].item()\n",
    "                #print(\"vhs=>\",pred_vhs)\n",
    "\n",
    "                 # Save predictions in CSV format\n",
    "                save_vhs_to_csv(name, pred_vhs)\n",
    "                \n",
    "\n",
    "            ## end : Loop through image names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy =>89.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\msnam\\.conda\\envs\\alz_chatbot\\lib\\site-packages\\graphviz\\backend\\execute.py:78\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m         proc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\msnam\\.conda\\envs\\alz_chatbot\\lib\\subprocess.py:493\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\msnam\\.conda\\envs\\alz_chatbot\\lib\\subprocess.py:858\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    855\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    856\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 858\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\msnam\\.conda\\envs\\alz_chatbot\\lib\\subprocess.py:1327\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1327\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1329\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1336\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1341\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 89\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Generate and render\u001b[39;00m\n\u001b[0;32m     88\u001b[0m graph \u001b[38;5;241m=\u001b[39m build_architecture()\n\u001b[1;32m---> 89\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmamba_architecture\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcleanup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\msnam\\.conda\\envs\\alz_chatbot\\lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\msnam\\.conda\\envs\\alz_chatbot\\lib\\site-packages\\graphviz\\rendering.py:122\u001b[0m, in \u001b[0;36mRender.render\u001b[1;34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001b[0m\n\u001b[0;32m    118\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(filename, directory\u001b[38;5;241m=\u001b[39mdirectory, skip_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    120\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(filepath)\n\u001b[1;32m--> 122\u001b[0m rendered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[0;32m    125\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelete \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, filepath)\n",
      "File \u001b[1;32mc:\\Users\\msnam\\.conda\\envs\\alz_chatbot\\lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\msnam\\.conda\\envs\\alz_chatbot\\lib\\site-packages\\graphviz\\backend\\rendering.py:326\u001b[0m, in \u001b[0;36mrender\u001b[1;34m(engine, format, filepath, renderer, formatter, neato_no_op, quiet, outfile, raise_if_result_exists, overwrite_filepath)\u001b[0m\n\u001b[0;32m    322\u001b[0m cmd \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m filepath \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwork around pytype false alarm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 326\u001b[0m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mfspath(outfile)\n",
      "File \u001b[1;32mc:\\Users\\msnam\\.conda\\envs\\alz_chatbot\\lib\\site-packages\\graphviz\\backend\\execute.py:81\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[1;32m---> 81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Color palette (matplotlib 'tab10' + custom)\n",
    "colors = {\n",
    "    \"stem\": mcolors.to_hex(\"tab:blue\"),\n",
    "    \"conv\": mcolors.to_hex(\"tab:cyan\"),\n",
    "    \"attention\": mcolors.to_hex(\"tab:orange\"),\n",
    "    \"se\": mcolors.to_hex(\"tab:green\"),\n",
    "    \"downsample\": mcolors.to_hex(\"tab:red\"),\n",
    "    \"regressor\": mcolors.to_hex(\"tab:purple\"),\n",
    "}\n",
    "\n",
    "def build_architecture():\n",
    "    dot = Digraph(comment=\"MambaKeypointRegressor\", format=\"png\")\n",
    "    dot.attr(rankdir=\"TB\", splines=\"ortho\", nodesep=\"0.5\", ranksep=\"0.8\")\n",
    "    dot.attr(\"node\", shape=\"box\", style=\"rounded,filled\", fontname=\"Helvetica\", fontsize=\"10\")\n",
    "\n",
    "    # ---- Input ----\n",
    "    dot.node(\"input\", \"Input Image\\n[1,3,512,512]\", shape=\"parallelogram\", color=\"black\")\n",
    "\n",
    "    # ---- Stem ----\n",
    "    with dot.subgraph(name=\"cluster_stem\") as c:\n",
    "        c.attr(label=\"MambaStem\", color=colors[\"stem\"], fontcolor=colors[\"stem\"])\n",
    "        c.node(\"stem_conv1\", \"Conv2d\\n3→64, stride=2\", color=colors[\"conv\"])\n",
    "        c.node(\"stem_norm1\", \"BatchNorm+SiLU\", color=colors[\"conv\"])\n",
    "        c.node(\"stem_conv2\", \"Conv2d\\n64→64\", color=colors[\"conv\"])\n",
    "        c.node(\"stem_norm2\", \"BatchNorm+SiLU\", color=colors[\"conv\"])\n",
    "        c.edges([(\"stem_conv1\", \"stem_norm1\"), (\"stem_norm1\", \"stem_conv2\"), (\"stem_conv2\", \"stem_norm2\")])\n",
    "\n",
    "    dot.edge(\"input\", \"stem_conv1\")\n",
    "\n",
    "    # ---- Stages ----\n",
    "    stages = [\n",
    "        {\"name\": \"Stage1\", \"in_ch\": 64, \"out_ch\": 128, \"depth\": 2, \"attention\": False},\n",
    "        {\"name\": \"Stage2\", \"in_ch\": 128, \"out_ch\": 256, \"depth\": 3, \"attention\": True},\n",
    "        {\"name\": \"Stage3\", \"in_ch\": 256, \"out_ch\": 512, \"depth\": 3, \"attention\": False},\n",
    "        {\"name\": \"Stage4\", \"in_ch\": 512, \"out_ch\": 640, \"depth\": 3, \"attention\": True},\n",
    "    ]\n",
    "\n",
    "    prev_node = \"stem_norm2\"\n",
    "    for stage in stages:\n",
    "        with dot.subgraph(name=f\"cluster_{stage['name']}\") as c:\n",
    "            c.attr(label=stage[\"name\"], color=colors[\"stem\"], fontcolor=colors[\"stem\"])\n",
    "            \n",
    "            # Downsample\n",
    "            c.node(f\"{stage['name']}_down\", \n",
    "                  f\"Downsample\\n{stage['in_ch']}→{stage['out_ch']}\", \n",
    "                  color=colors[\"downsample\"])\n",
    "            dot.edge(prev_node, f\"{stage['name']}_down\")\n",
    "            \n",
    "            # Residual + Attention/SE Blocks\n",
    "            for d in range(stage[\"depth\"]):\n",
    "                c.node(f\"{stage['name']}_res{d}\", \n",
    "                      f\"ResidualBlock\\n{stage['out_ch']}→{stage['out_ch']}\", \n",
    "                      color=colors[\"conv\"])\n",
    "                c.node(f\"{stage['name']}_att{d}\", \n",
    "                      \"AttentionMLP\" if stage[\"attention\"] else \"SELayer\", \n",
    "                      color=colors[\"attention\"] if stage[\"attention\"] else colors[\"se\"])\n",
    "                \n",
    "                if d == 0:\n",
    "                    c.edge(f\"{stage['name']}_down\", f\"{stage['name']}_res{d}\")\n",
    "                else:\n",
    "                    c.edge(f\"{stage['name']}_att{d-1}\", f\"{stage['name']}_res{d}\")\n",
    "                \n",
    "                c.edge(f\"{stage['name']}_res{d}\", f\"{stage['name']}_att{d}\")\n",
    "            \n",
    "            prev_node = f\"{stage['name']}_att{stage['depth']-1}\"\n",
    "\n",
    "    # ---- Regressor ----\n",
    "    with dot.subgraph(name=\"cluster_regressor\") as c:\n",
    "        c.attr(label=\"Regressor\", color=colors[\"regressor\"], fontcolor=colors[\"regressor\"])\n",
    "        c.node(\"pool\", \"GlobalAvgPool2d\\n[1,640,1,1]\", shape=\"ellipse\")\n",
    "        c.node(\"flatten\", \"Flatten\\n→640\", shape=\"ellipse\")\n",
    "        c.node(\"linear1\", \"Linear\\n640→384\")\n",
    "        c.node(\"linear2\", \"Linear\\n384→12\")\n",
    "        c.edges([(\"pool\", \"flatten\"), (\"flatten\", \"linear1\"), (\"linear1\", \"linear2\")])\n",
    "\n",
    "    dot.edge(prev_node, \"pool\")\n",
    "\n",
    "    # ---- Output ----\n",
    "    dot.node(\"output\", \"Keypoints\\n[1,12]\", shape=\"parallelogram\", color=\"black\")\n",
    "    dot.edge(\"linear2\", \"output\")\n",
    "\n",
    "    return dot\n",
    "\n",
    "# Generate and render\n",
    "graph = build_architecture()\n",
    "graph.render(\"mamba_architecture\", view=True, cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.20.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alz_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
